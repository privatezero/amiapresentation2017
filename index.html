<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Perceptual Hashing!</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section data-markdown>
					<textarea data-template>
					### Automation and Similarity: An Introduction to Perceptual Hashing
					#### Andrew Weaver
					Washington State University Libraries
					</textarea>
				</section>

				<section data-markdown>
					<textarea data-template>
					### What is perceptual hashing??
					* Create links between materials in the way a human would percieve them
					* Kind of like fixity for content instead of file integrity
					</textarea>
				</section>
				<section data-background-image=Resources/mixedcolorspaceneedle.jpg>
				<div class="contrast">
				<p>Left and right image same to viewer ; totally different to computer</p>
				<div class="citation">
				<p><a href="http://archiveswest.orbiscascade.org/ark:/80444/xv53979">Image Source MOHAI/UW Special Collections</a></p>
				</div>
				</div>
				</section>

				<section data-background-image=Resources/mixedcolorspaceneedle.png>
				<div class="contrast">
				<p>Previous Slide Background was .jpg, This slide is .png</p>
				<div class="citation">
				<p><a href="http://archiveswest.orbiscascade.org/ark:/80444/xv53979">Image Source MOHAI/UW Special Collections</a></p>
				</div>
				</div>
				</section>

                <section data-markdown>
                    <textarea data-template>
                    #### Problem: How to make content machine readable?
                    ##### Answer: Transformations (lots of 'em!)
                    </textarea>
                </section>

				<section data-markdown>
					<textarea data-template>
					#### Audio Hashing using Chromaprint (and [pyacoustid](https://pypi.python.org/pypi/pyacoustid))
					</textarea>
				</section>

				<section data-markdown>
					<textarea data-template>
					Chromaprint Library: Converts audio input to a sample rate of 11025 Hz before generating representations of the content in musical notes (ignoring octave) via frequency analysis which are THEN subjected to a series of filters which create the final fingerprint.
					</textarea>
				</section>

				<section>
					<div class="citation">
					<p>https://oxygene.sk/2011/01/how-does-chromaprint-work</p>
					</div>
					<img src="Resources/chromaprint.png" alt="Chromaprint example" width=40% height=40%>
				</section>

				<section data-markdown>
					<textarea data-template>
					#### Video hashing using MPEG-7 Standard (and [FFmpeg](https://avpres.net/FFmpeg/#ch1))
					</textarea>
				</section>

				<section data-markdown>
					<textarea data-template>
					Down converts each frame to 32x32 8 bit images and extracts series of averages and differences of the luma content for subsections of new frames. Elements of these frame signatures are then plotted on a histogram in 90 frame chunks, which is then 'binarized' to create rough signatures.
					</textarea>
				</section>

                <section>
                    <div class="citation">
                    <p>Chiariglione, L. (2012). The MPEG representation of digital media. (pp. 88). New York, NY: Springer.</p>
                    </div>
                    <img src="Resources/lumafingerprint.png" alt="Video hash sampling" width=40% height=40%>
                </section>

				<section data-background-iframe="https://archive.org/details/SMA_524" data-background-interactive>
					<div class="contrast">
						<pre><h3>Video Source</h3></pre>
					</div>
				</section>

				<section data-background-video="Resources/ballard.ogv" data-background-video-loop data-background-video-muted>
					<pre><code data-trim data-noescape>
					ffmpeg -i https://archive.org/download/SMA_524/SMA_5153.mp4 \
					-i 'https://privatezero.github.io/amiapresentation2017/Resources/ballard.ogv' \
					-filter_complex signature=detectmode=full:nb_inputs=2 -f null -
					</code></pre>
				</section>

				<section>
					<code>[Parsed_signature_0 @ 0x126cc00] matching of video 0 at 581.672567 and 1 at 1.668333, 295 frames matching
[Parsed_signature_0 @ 0x126cc00] whole video matching</code>
				</section>

				<section data-markdown>
					<textarea data-template>
					#### Experimental application at CUNY-TV
					</textarea>
				</section>

				<section data-markdown>
					<textarea data-template>
					* Create Fingerprints
					
					[Bash script](https://github.com/mediamicroservices/mm/blob/master/makefingerprint) controlling FFmpeg

					* Store Fingerprints
					
					[Bash functions](https://github.com/mediamicroservices/mm/blob/master/mmfunctions#L108) parsing XML output of fingerprints to DB/Adding to AIPs

					* Query Fingerprints
					
					[Bash script](https://github.com/mediamicroservices/mm/blob/master/searchfingerprint) controlling FFmpeg and FFplay to generate/compare fingerprint/time stamp against stored fingerprints and display video of matches.
					</textarea>
				</section>
				<section>
                    <p>Each ninety frame 'Rough Signature' consisting of five 'BagOfWords' sections stored in database corresponding in/out frame numbers.
					<pre><code data-trim>
					<BagOfWords>0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0  1  0  0  0  0  0  0  0  0  0 </BagOfWords>
					</code></pre>
				</section>

				<section>
				<pre><code data-trim data-noescape>searchfingerprint -i 70 -o 85 ~/Desktop/temple.mp4</code></pre>
				<img src="Resources/results.gif" alt="Eddie Veddar results">
				<div class=citation>
				<p>Sample footage copyright Temple of the Dog/A&amp;M Records</p>
				</div>
				</section>

				<section data-background-iframe="https://amiaopensource.github.io/ffmprovisr/#generate_video_fingerprint" data-background-interactive>
					<div class="contrast">
						<pre><h3>https://amiaopensource.github.io/ffmprovisr</h3></pre>
					</div>
				</section>

				<section data-markdown>
					<textarea data-template>
					### Resources
					* [MPEG Representation of Digital Media](http://www.worldcat.org/oclc/902763394)
					* [How Does Chromaprint Work?](https://oxygene.sk/2011/01/how-does-chromaprint-work/)
					* [Adventures in Perceptual Hashing](https://privatezero.github.io/weaverblog/2017/04/18/Adventures-in-perceptual-hashing.html)
					#### Tools
					* [AccoustID](https://acoustid.org/)
					* [FFmpeg](https://www.ffmpeg.org/)

					</textarea>
				</section>

			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
